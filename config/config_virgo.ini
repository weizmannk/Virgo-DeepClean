[config]

# Condor properties
job_name = O3b_Virgo_Virgo_142-162_Hz_4096
universe = vanilla
accounting_group = ligo.dev.o4.detchar.subtraction.deepclean
request_memory_training = 4 GB
request_memory_cleaning = 8 GB

request_disk_training   = 8 GB
request_disk_cleaning   = 8 GB


# Input/output properties
# Output files are produced in the format: {prefix}_{t0}-{duration}.gwf
# Channel name is {out_channel}
out_dir = 4096
prefix = Hrec-HOFT
out_channel = V1:Hrec_hoft_raw_20000Hz_DC

# inteferometer to use (either H1 , L1 or V1)
ifo = V1

# if True, will save the original dataset (not just the clean dataset)
save_dataset = True

# load_dataset = False

# Dataset properties

##Â the Run O3b, june 2023
# march 8th 2020

# starting GPS time
#t0 = 1262676041

#t1 = 1262679041
# stopping GPS time
#t1 = 1262909219

t0 = 1265127585

#t1 = 1265136585


# stopping GPS time
t1 = 1265366119


# sampling rate
fs = 4096

# channel list to use
chanslist = ./witnesses_142-162.ini
# cache files
cache_file = /home/weizmann.kiendrebeogo/DeepClean/DeepClean_CIT/V1-O3b_1265100000-1265399999.cache

# maximum cleaning duration
max_clean_duration = 4096

# Data preprocessing properties
# The raw timeseries is divided into smaller, overlapping segments
# Each segment has a length of {kernel} seconds
# Stepsize is {stride} seconds, which can be different for training vs cleaning
# The last segment is padded using {pad_mode} method if there isn't enough sample
train_kernel = 8
train_stride = 0.25
clean_kernel = 8
clean_stride = 4
pad_mode = median

# Raw timeseries are bandpassed from {filt_fl} to {filt_fh}
# with a filtering order of {filt_order}
# after bandpassong, the window of type {window} is applied
window = hanning
filt_fl = 142
filt_fh = 162
filt_order = 8

# Training properties
# GPU device
device = cuda
# partition between training/validation set
train_frac = 0.9
batch_size = 32
max_epochs = 30
# number of workers for Pytorch DataLoader
num_workers = 4

# duration in seconds
train_duration = 4096

# cadence in seconds
train_cadence  = 100000
# if this is set to non-zero value (say T), then the first T seconds of each segment is not used for training. ie, the first train-t0 is shifted by T.
# The very begining of a segment is sometimes noisy and may not represent the coupling afterwards.
start_training_after = 600

# learning rate of Adam optimizer
lr = 1e-3

# weight decay of Adam optimizer
weight_decay = 1e-5

# Loss function: L = {psd_weight} * PSDLoss + {mse_weight} * MSELoss
# {fftlength} (in seconds) is the length of the Fourier Transform to
# calculate Welch's PSD in PSDLoss
fftlength = 2
psd_weight = 1.0
mse_weight = 0.0

# Summary page settings
# For creating summary page after cleaning, NOT YET IMPLEMENTED
fftlength_spec = 1.25
fftlength_asd = 8.0
asd_min = 1e-24
asd_max = 1e-20
asd_whiten_min = 1e-3
asd_whiten_max = 10
